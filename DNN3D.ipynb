{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "5c591fa902ef7847f21c744999e6dcc6899faa0d70e0fadd24d5d8de1c6e18ef"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pprint import pprint as pp\n",
    "from time import time as tt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d as plt3d\n",
    "import matplotlib.colors\n",
    "# from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "print(\"PyTorch version:\",print(torch.__version__),\", CUDA version:\", torch.version.cuda)\n",
    "# from torch_geometric.data import Data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch_scatter import scatter_add\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Get rid of RuntimeWarnings, gross\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_x = [-999, -21, 151, 497, 843.7, 1141, 1266, 1960]\n",
    "layers_y = [-16, 131, 477, 832, 1146, 1479.6, 1973 ]\n",
    "layers_ordered = [-16, -21, 131, 151, 477, 497, 832, 832, 843.7, 843.7, 1146, 1146, 1141, 1141, 1252.7, 1252.7, 1266, 1266, 1479.6, 1479.6, 1467.4, 1467.4, 1973, 1973, 1960, 1960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read hits\n",
    "def readMuonE(event_file):\n",
    "   data = pd.read_csv(event_file) \n",
    "   \n",
    "   iEventLast=data.iat[0,0]\n",
    "   k=0\n",
    "   dataOUT = []\n",
    "\n",
    "   #iterate over input data\n",
    "   for k, row in data.iterrows():\n",
    "     e = int(row[0])\n",
    "     if len(dataOUT) < e:\n",
    "       dataOUT.append([])\n",
    "     dataOUT[e-1].extend([row[1], row[3]])\n",
    "\n",
    "   return dataOUT       \n",
    "\n",
    "# Read slopes of MC tracks\n",
    "def readMCslopes(event_file):  \n",
    "  data = pd.read_csv(event_file) \n",
    "  \n",
    "  temp=data.iat[-1,0] # number of events\n",
    "  track_slopes_x=torch.zeros(temp,6)\n",
    "  track_slopes_y=torch.zeros(temp,6)\n",
    "\n",
    "  axis_oi=[4,1]\n",
    "  for k, row in data.iterrows():\n",
    "    if row[7] in (0,1,2):\n",
    "      if track_slopes_x.shape[0]< row[0]-1 :\n",
    "        track_slopes_x=torch.cat([track_slopes_x,torch.zeros(1,6)],dim=0)\n",
    "      track_slopes_x[int(row[0])-1,int(row[7]*2) ] = row[axis_oi[0]]/row[6]\n",
    "      track_slopes_x[int(row[0])-1,int(row[7])*2+1] =  row[axis_oi[1]] - row[axis_oi[0]]/row[6]  * row[3]\n",
    "  \n",
    "  axis_oi=[5,2]\n",
    "  for k, row in data.iterrows():\n",
    "    if row[7] in (0,1,2):\n",
    "      if track_slopes_y.shape[0]< row[0]-1 :\n",
    "        track_slopes_y=torch.cat([track_slopes_y,torch.zeros(1,6)],dim=0)\n",
    "      track_slopes_y[int(row[0])-1,int(row[7]*2) ] = row[axis_oi[0]]/row[6]\n",
    "      track_slopes_y[int(row[0])-1,int(row[7])*2+1] =  row[axis_oi[1]] - row[axis_oi[0]]/row[6]  * row[3]\n",
    "\n",
    "  return np.concatenate((track_slopes_x, track_slopes_y), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read data and prepare for training\n",
    "\n",
       "event_file_MC= \"path\\\\to\\\\MCtrackFile_big.csv\"\n",
    "event_file= \"path\\\\to\\\\hitFile_big.csv\"\n",
    "event_file_recon= \"path\\\\to\\\\trackFile_big.csv\"\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "hit = readMuonE(event_file)\n",
    "print(\"readMuonE\\t--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(len(hit))\n",
    "\n",
    "start_time = time.time()\n",
    "mc = readMCslopes(event_file_MC)\n",
    "print(\"readMCtrack\\t--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(len(mc))\n",
    "\n",
    "# split data into training and test datasets\n",
    "train_dataset_,test_dataset_,test_tracks,train_tracks,train_recon,test_recon, train_mc_, test_mc_ = [],[],[],[],[],[],[],[]\n",
    "for k in range(len(hit)):\n",
    "  # skip not full-length events\n",
    "  if len(hit[k]) != 52 or len(mc[k]) != 12:\n",
    "      continue\n",
    "  if (k%4 == 0):\n",
    "    test_dataset_.append(hit[k])\n",
    "    test_mc_.append(mc[k])\n",
    "  else:\n",
    "    train_dataset_.append(hit[k])\n",
    "    train_mc_.append(mc[k])\n",
    "print(len(train_dataset_))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler, MaxAbsScaler\n",
    "import sklearn.preprocessing\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_dataset_)\n",
    "train_dataset = scaler.transform(train_dataset_)\n",
    "\n",
    "scaler.fit(test_dataset_)\n",
    "test_dataset = scaler.transform(test_dataset_)\n",
    "\n",
    "train_mc = train_mc_\n",
    "test_mc = test_mc_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn datasets into tensors\n",
    "train_dataset = torch.Tensor(train_dataset).cuda()\n",
    "train_dataset.requires_grad_(True)\n",
    "train_mc = torch.Tensor(train_mc).cuda()\n",
    "train_mc.requires_grad_(True)\n",
    "\n",
    "test_dataset = torch.Tensor(test_dataset)\n",
    "test_mc = torch.Tensor(test_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(52, 500)\n",
    "        self.fc2 = nn.Linear(500, 500)\n",
    "        self.fc3 = nn.Linear(500, 500)\n",
    "        # self.fc32 = nn.Linear(500, 500)\n",
    "        # self.fc33 = nn.Linear(500, 500)\n",
    "        self.fc4 = nn.Linear(500, 500)\n",
    "        self.fc5 = nn.Linear(500, 12)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # x = F.relu(self.fc32(x))\n",
    "        # x = F.relu(self.fc33(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# traint he model\n",
    "\n",
    "losses = []\n",
    "model = Model()\n",
    "model.cuda()\n",
    "crit = torch.nn.MSELoss().cuda() #nn.L1Loss().cuda()\n",
    "# crit = torch.nn.L1Loss().cuda()\n",
    "optimizer =  optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-3, amsgrad=True)\n",
    "# optimizer = torch.optim.SGD(net.parameters(), lr=1e-5, momentum=0.3)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(10001):  # loop over the dataset multiple times\n",
    "    outputs = model(train_dataset)\n",
    "    loss = crit(outputs, train_mc)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch%100==0:\n",
    "        print('epoch {}\\tloss {}'.format(epoch, loss))\n",
    "        losses.append([epoch, loss])\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw slopes\n",
    "def plotxy(pred, mc, hits):\n",
    "    z = np.linspace(-21, 2000, endpoint=True)\n",
    "\n",
    "    mc1 = mc[2]*z+mc[3]\n",
    "    mc2 = mc[4]*z+mc[5]\n",
    "    mc3 = mc[8]*z+mc[9]\n",
    "    mc4 = mc[10]*z+mc[11]\n",
    "\n",
    "    pred1 = pred[2]*z+pred[3]\n",
    "    pred2 = pred[4]*z+pred[5]\n",
    "    pred3 = pred[8]*z+pred[9]\n",
    "    pred4 = pred[10]*z+pred[11]\n",
    "\n",
    "    fig=plt.figure(figsize=(20,10))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(z, mc1, 'k', alpha=0.4)\n",
    "    plt.plot(z, mc2, 'k', alpha=0.4)\n",
    "    plt.plot(z, pred1, 'r')\n",
    "    plt.plot(z, pred2, 'g')\n",
    "    for i in range(int(len(hits)/2)):\n",
    "        if hits[2*i+1] in layers_x:\n",
    "            plt.scatter(hits[2*i+1], hits[2*i], c='k')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(z, mc3, 'k', alpha=0.4)\n",
    "    plt.plot(z, mc4, 'k', alpha=0.4)\n",
    "    plt.plot(z, pred3, 'r')\n",
    "    plt.plot(z, pred4, 'g')\n",
    "    for i in range(int(len(hits)/2)):\n",
    "        if hits[2*i+1] in layers_y:\n",
    "            plt.scatter(hits[2*i+1], hits[2*i], c='k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot some results\n",
    "model.eval()\n",
    "model.cpu()\n",
    "for i in range(0,20):\n",
    "    data = test_dataset[i]\n",
    "    preds=model(data).detach().numpy()\n",
    "    plotxy(preds, test_mc[i], test_dataset_[i])"
   ]
  }
 ]
}